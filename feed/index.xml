<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Intro to becoming an AI ninja</title>
	<atom:link href="https://rettend.github.io/feed/" rel="self" type="application/rss+xml" />
	<link>https://rettend.github.io</link>
	<description></description>
	<lastBuildDate>Fri, 09 Dec 2022 08:21:21 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.1.1</generator>
	<item>
		<title>THE GRIND</title>
		<link>https://rettend.github.io/2022/12/07/grind/</link>
					<comments>https://rettend.github.io/2022/12/07/grind/#respond</comments>
		
		<dc:creator><![CDATA[asd]]></dc:creator>
		<pubDate>Wed, 07 Dec 2022 17:45:11 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">https://rettend.github.io/?p=136</guid>

					<description><![CDATA[Ez a lehet≈ë legjobb tutorial amit eddig l√°ttam, v√©gigmegy a matekon √©s python p√©ld√°kat hoz, valamint a lehet≈ë legeslegelej√©r≈ël kezd bele.(m√©g b≈ëv√ºl≈ë playlist) Tov√°bbi oldalak:]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image aligncenter size-full is-resized"><img decoding="async" src="https://rettend.github.io/wp-content/uploads/2022/12/stick-ninja-sword.png" alt="" class="wp-image-140" width="234" height="226"/></figure>



<p>Ez a lehet≈ë legjobb tutorial amit eddig l√°ttam, v√©gigmegy a matekon √©s python p√©ld√°kat hoz, valamint a lehet≈ë legeslegelej√©r≈ël kezd bele.<br>(m√©g b≈ëv√ºl≈ë playlist)</p>



<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe loading="lazy" title="The spelled-out intro to neural networks and backpropagation: building micrograd" width="500" height="281" src="https://www.youtube.com/embed/VMj-3S1tku0?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div></figure>



<p class="has-medium-font-size">Tov√°bbi oldalak:</p>



<ul class="has-small-font-size">
<li><a rel="noreferrer noopener" href="https://huggingface.co/course/chapter1/1" target="_blank">Introduction &#8211; Hugging Face Course</a></li>



<li><a rel="noreferrer noopener" href="https://d2l.ai/chapter_preface/index.html" target="_blank">Preface ‚Äî Dive into Deep Learning</a></li>



<li><a href="https://www.tensorflow.org/resources/learn-ml">Machine learning education &nbsp;|&nbsp; TensorFlow</a></li>



<li><a href="https://cs231n.github.io/">CS231n Convolutional Neural Networks for Visual Recognition</a></li>
</ul>
]]></content:encoded>
					
					<wfw:commentRss>https://rettend.github.io/2022/12/07/grind/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Transformer: Meme your way to greatness</title>
		<link>https://rettend.github.io/2022/12/06/transformer/</link>
					<comments>https://rettend.github.io/2022/12/06/transformer/#respond</comments>
		
		<dc:creator><![CDATA[asd]]></dc:creator>
		<pubDate>Tue, 06 Dec 2022 19:27:00 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">https://rettend.github.io/?p=110</guid>

					<description><![CDATA[4 skill kell az AI-hoz: Coding: a programoz√°s r√©sz, √©s sok nyelv k√∂z√ºl v√°laszthatunk szerencs√©re. Ez a Python-n√°l a Tensorflow-n √©s a PyTorch-on kereszt√ºl, webes projektekhez JavaScript, de l√©tezik ML.NET is. Math: deriv√°l√°s √©s kalkulus az alapja a neur√°lis h√°l√≥zatok m≈±k√∂d√©s√©nek. A k√∂vetkez≈ë fejezetben ezt azonnal orvosolni fogjuk. ML theory: a fogalmak √©s mechanik√°k jelent√©s√©vel [&#8230;]]]></description>
										<content:encoded><![CDATA[
<p>4 skill kell az AI-hoz:</p>



<div class="is-layout-flex wp-container-3 wp-block-columns">
<div class="is-layout-flow wp-block-column" style="flex-basis:60px">
<figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="77" height="445" src="https://rettend.github.io/wp-content/uploads/2022/12/image-24.png" alt="" class="wp-image-147"/></figure>
</div>



<div class="is-layout-flow wp-block-column" style="padding-top:0px;padding-right:0;padding-bottom:0;padding-left:0">
<p class="has-background" style="background-color:#1b1b1b;margin-top:0px;margin-right:0px;margin-bottom:0px;margin-left:0px;padding-top:10px;padding-right:10px;padding-bottom:10px;padding-left:10px"><strong>Coding</strong>: a programoz√°s r√©sz, √©s sok nyelv k√∂z√ºl v√°laszthatunk szerencs√©re. Ez a Python-n√°l a Tensorflow-n √©s a PyTorch-on kereszt√ºl, webes projektekhez JavaScript, de l√©tezik ML.NET is.</p>



<p class="has-background" style="background-color:#1b1b1b;margin-top:17px;padding-top:10px;padding-right:10px;padding-bottom:10px;padding-left:10px"><strong>Math</strong>: deriv√°l√°s √©s kalkulus az alapja a neur√°lis h√°l√≥zatok m≈±k√∂d√©s√©nek. A k√∂vetkez≈ë fejezetben ezt azonnal orvosolni fogjuk.</p>



<p class="has-background" style="background-color:#1b1b1b;margin-top:16px;padding-top:10px;padding-right:10px;padding-bottom:10px;padding-left:10px"><strong>ML theory</strong>: a fogalmak √©s mechanik√°k jelent√©s√©vel tiszt√°ban kell lenn√ºnk, valamint a k√ºl√∂nb√∂z≈ë architekt√∫r√°k m≈±k√∂d√©s√©vel is.</p>



<p class="has-background" style="background-color:#1b1b1b;margin-top:16px;padding-top:12px;padding-right:12px;padding-bottom:12px;padding-left:12px"><strong>Projects</strong>: az el≈ëz≈ë 3 hi√°baval√≥ ha nem tudjuk be√©p√≠teni az appunkba.</p>
</div>
</div>



<p>Sz√≥val itt kicsit megismerked√ºnk a men≈ë Transformer modellel, majd a k√∂vetkez≈ë fejezetben nekil√°tunk a 4 skill-nek. Ennek most a l√©nyege, hogy √°tl√°ssuk nagyvonalakban a modellhez vezet≈ë utat, valamint a v√©g√©n az AI j√∂v≈ëj√©t mert el√©g hype.</p>



<figure class="wp-block-image aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="https://rettend.github.io/wp-content/uploads/2022/12/stick-ninja-jump.png" alt="" class="wp-image-149" width="168" height="240"/></figure>



<p class="has-cyan-bluish-gray-color has-text-color">(Most √≠rok egy posztot ami egy nagyon j√≥ √©s hossz√∫ quora v√°laszra √©p√ºl, ami egy medium posztra √©p√ºl, meg arr√≥l amire meg a medium poszt √©p√ºl ami egy random blog. Sz√≥√≥val, nem √≠rok forr√°sokat ink√°bb.)</p>



<p>A Transformer-ig vezet≈ë √∫t egy egyszer≈± probl√©m√°val kezd≈ëdik: sequence transduction. Ami l√©nyeg√©ben <strong>transzform√°ci√≥t </strong>jelent, m√©gpedig olyan feladatokn√°l, ahol egy sorozatot egy teljesen m√°s szerkezet≈± sorozatt√° szeretn√©nk √°talak√≠tani, de √∫gy, hogy meg≈ërizze az inform√°ci√≥tartalm√°t. Egyszer≈± p√©lda erre a g√©pi ford√≠t√°s √©s a besz√©dfelismer√©s. </p>



<figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="600" height="180" src="https://rettend.github.io/wp-content/uploads/2022/12/main-qimg-d8239c14d83a3343f34a61c43a3e98a7.gif" alt="" class="wp-image-155"/></figure>



<p>A z√∂ld az input sorozat, a lila pedig az output sorozat. Ezek a sorozatok szavakb√≥l √°llnak √©s egym√°s ut√°n dolgozza fel ≈ëket a k√©k modell.  </p>



<figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="600" height="180" src="https://rettend.github.io/wp-content/uploads/2022/12/seq2seq_2-1.gif" alt="" class="wp-image-161"/></figure>



<p>A modell, egy encoder-b≈ël √°ll ami √©rtelmezi az inputot, √©s egy decoder-b≈ël ami az outputot gener√°lja az encoder inform√°ci√≥i alapj√°n.</p>



<figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="600" height="160" src="https://rettend.github.io/wp-content/uploads/2022/12/seq2seq_4.gif" alt="" class="wp-image-164"/></figure>



<p>Az els≈ë dolog ami felmer√ºl az az, hogy kell a modellnek adnunk valamif√©le mem√≥ri√°t. N√©zz√ºk meg a k√∂vetkez≈ë mondatot: <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f44d.png" alt="üëç" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>



<p><em> ‚ÄúThe Transformers&#8217; are a Japanese [[hardcore punk]] band. The band was formed in 1968, during the height of Japanese music history‚Äù</em></p>



<p>A m√°sodik mondatban a &#8220;band&#8221; meg√©rt√©s√©hez kellene tudnunk, hogy mire hivatkozik az, itt m√©gpedig a &#8220;Transformers&#8221;-re. Erre klasszikus architekt√∫r√°kat haszn√°ltak, mint az RNN √©s a CNN.</p>



<p class="has-medium-font-size">RNN: Recurrent Neural Network</p>



<p>Nev√ºket a visszat√©r≈ë elem√ºkr≈ël kapt√°k. Az <strong>A</strong> modellnek lesz egy bels≈ë √°llapota (mem√≥ria, cell state) X<sub>t</sub> √©rtelmez√©se ut√°n, amit k√©pes felhaszn√°lni √∫jra a k√∂vetkez≈ë input fogad√°s√°n√°l. Ezzel √©szben tudja tartani az el≈ëz≈ë inputb√≥l az inform√°ci√≥t, kontextust hozva l√©tre.</p>



<figure class="wp-block-image aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="https://rettend.github.io/wp-content/uploads/2022/12/image-32.png" alt="" class="wp-image-173" width="181" height="253"/></figure>



<p>Hogy jobban meg√©rts√ºk, k√©pzelj√ºk el, hogy &#8220;kicsomagoljuk&#8221; azt a hurkot. √çgy l√©nyeg√©ben t√∂bb FNN (Feedforward Neural Network), ami a legegyszer≈±bb neur√°lis h√°l√≥zat fajta, √≠gy nincs k√ºl√∂n mit magyar√°zni rajta.</p>



<figure class="wp-block-image aligncenter size-full"><img decoding="async" loading="lazy" width="1156" height="357" src="https://rettend.github.io/wp-content/uploads/2022/12/image-33.png" alt="" class="wp-image-174"/></figure>



<p>Minden egyes X inputhoz az A modell √≠gy az inputot mag√°t √©s az el≈ëz≈ë A modell √°llapot√°t veszi be. </p>



<figure class="wp-block-image size-full is-resized"><img decoding="async" loading="lazy" src="https://rettend.github.io/wp-content/uploads/2022/12/main-qimg-24efe1c6eb254fc229e85f07ed01fa44.gif" alt="" class="wp-image-171" width="600" height="265"/></figure>



<p>Ez a m√≥dszer addig √°llja a hely√©t, am√≠g az input sz√≥, √©s ahol a decoder-nek sz√ºks√©ge van az inform√°ci√≥j√°ra k√∂zel van egym√°shoz. Az inform√°ci√≥ ugyanis csak egy utat k√∂vet √©s minden egyes l√©p√©sn√©l n≈ë a val√≥sz√≠n≈±s√©ge, hogy elveszik. </p>



<p class="has-medium-font-size">LSTM: Long-Short Term Memory</p>



<figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="871" height="322" src="https://rettend.github.io/wp-content/uploads/2022/12/image-35.png" alt="" class="wp-image-176"/></figure>



<p class="has-text-align-center has-cyan-bluish-gray-color has-text-color" style="margin-top:0px">RNN</p>



<p>Az LSTM megold√°sa erre az, hogy megpr√≥b√°lja eld√∂nteni, hogy mennyire √©rdemes megjegyezni az inform√°ci√≥t. K√≠v√ºlr≈ël a k√©t h√°l√≥zat majdnem megegyezik, A lentiben azonban az el≈ëz≈ë encoder √°llapota (hidden state) is tov√°bbad√≥dik (nem csak a cell state).</p>



<figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="865" height="348" src="https://rettend.github.io/wp-content/uploads/2022/12/image-31.png" alt="" class="wp-image-172"/></figure>



<p class="has-text-align-center has-contrast-color has-text-color" style="margin-top:0px">LSTM</p>



<p>A pontos jelek egyszer≈±bbek mint gondoln√°nk: a tanh() csak -1 √©s 1 k√∂z√© helyezi az √©rt√©keket ar√°nyosan, azt√°n szorz√°sok √©s √∂sszead√°sok vannak, valamint a 3 szigmoid f√ºggv√©ny sorrendben: a felejt√©st, az √∫j inform√°ci√≥ hozz√°ad√°s√°t, √©s az output-ot vez√©rlik. A l√©nyeg az, hogy lehet≈ës√©ge van a context-nek modifik√°ci√≥ n√©lk√ºl tov√°bbhaladnia:</p>



<figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="1826" height="564" src="https://rettend.github.io/wp-content/uploads/2022/12/image-34.png" alt="" class="wp-image-175"/></figure>



<p>Sz√≥val a fels≈ë √∫t a cell state √∫tja, az als√≥ pedig az √∫j hidden state-√©. Ez a k√©t vektor k√∂z√ºl a fels≈ë ami az addigi encoder-ek modifik√°ci√≥it √°ltal√°nosabban √≠rja le (mivel kihagyja a szigmoid f√ºggv√©nyeket). M√≠g az als√≥ az adott encoder d√∂nt√©seit tartalmazza a kapott inform√°ci√≥ alapj√°n. Innen j√∂n a n√©v: <strong>long-short</strong> term memory.</p>



<p>A probl√©m√°nk tov√°bbra is jelen van azonban: egy id≈ë ut√°n elveszik a fontos szavak inform√°ci√≥ja is. Ezenk√≠v√ºl, az ilyen h√°l√≥zatokat egy√°ltal√°n nem lehet p√°rhuzamosan futtatni, minden sz√≥ feldolgoz√°sa el≈ëtt tudnunk kell az addigiak inform√°ci√≥it, hogy mennyire befoly√°solj√°k az encoder d√∂nt√©s√©t. Nagy problem!</p>



<p class="has-medium-font-size">Attention</p>



<p>Oldjuk meg a felejt√©st els≈ënek, amire behozzuk az attention mechanizmus. Ennek l√©nyege, hogy a decoder-nek j√≥ lenne tudnia az egyes encoder-ek hidden state-jeir≈ël k√ºl√∂n.</p>



<figure class="wp-block-image size-full is-resized"><img decoding="async" loading="lazy" src="https://rettend.github.io/wp-content/uploads/2022/12/main-qimg-24efe1c6eb254fc229e85f07ed01fa44.gif" alt="" class="wp-image-171" width="600" height="265"/></figure>



<p class="has-text-align-center has-cyan-bluish-gray-color has-text-color" style="margin-top:0px">simple RNN</p>



<figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="600" height="263" src="https://rettend.github.io/wp-content/uploads/2022/12/main-qimg-3dca0e695b3011a635e23d29689d5142.gif" alt="" class="wp-image-179"/></figure>



<p class="has-text-align-center has-cyan-bluish-gray-color has-text-color" style="margin-top:0px">RNN with attention decoders</p>



<p>Ennek eredm√©nyek√©ppen, a decoder tudja az √∂sszes sz√≥r√≥l azt, hogy mennyire van k√∂z√ºk ahhoz az egy sz√≥hoz amit ≈ë gener√°l. √âs ezzel a t√∂bbi decoder is √≠gy van. N√©zz√ºnk egy p√©ld√°t, amikoris egy francia mondatot szeretn√©nk angolra leford√≠tani:</p>



<figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="600" height="261" src="https://rettend.github.io/wp-content/uploads/2022/12/main-qimg-a6d7419d81762e37fa7a1b1288416c86.gif" alt="" class="wp-image-180"/></figure>



<p>A hidden state-k √©rt√©ke min√©l nagyon ann√°l t√∂bb k√∂z√ºk van az adott sz√≥hoz (√©s ann√°l s√∂t√©tebb a sz√≠n√ºk). L√°thatod, hogy az angol &#8220;a&#8221; n√©vel≈ë nem tal√°lhat√≥ meg a francia mondatban (ha sz√≥r√≥l sz√≥ra ford√≠tan√°nk le), helyette az utols√≥ k√©t francia sz√≥ hordozza az inform√°ci√≥j√°t mag√°val.</p>



<p class="has-medium-font-size">CNN: Convolutional Neural Networks</p>



<p>A p√°rhuzamoss√°got egy m√°sik klasszikus architekt√∫r√°val oldjuk meg. A CNN-eket egy√©bk√©nt f≈ëleg k√©pfelismer√©shez haszn√°lj√°k, de nem kiz√°r√≥lag.</p>



<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe loading="lazy" title="But what is a convolution?" width="500" height="281" src="https://www.youtube.com/embed/KuXjwB4LzSA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div></figure>



<p>Teh√°t nagyon gyors, mivel minden sz√≥ feldolgoz√°sa t√∂rt√©nhet egym√°s mellett. √âs a t√°vols√°g az egyes input szavak √©s az output szavak k√∂z√∂tt log(N), √©s nem N mint az RNN-ekn√©l, sz√≥val sokkal jobban is scale-el. A sima CNN h√°l√≥zatokn√°l azonban elveszik az inform√°ci√≥, nem rendelkeznek attention-el.</p>



<p class="has-medium-font-size">Transformer</p>



<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-4-3 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe loading="lazy" title="The Emperors New Groove: Oh Yeah It&#039;s All Coming Together" width="500" height="375" src="https://www.youtube.com/embed/QyrDgEz3DR0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div></figure>



<p>√Åtlagos tudom√°nyos publik√°ci√≥k c√≠me: (random tal√°ltam)<br>&#8211; Isotropization and Complexity of Decoupled Solutions in Self-interacting Brans-Dicke Gravity</p>



<p>AI pap√≠rok:<br>&#8211; <a rel="noreferrer noopener" href="https://arxiv.org/abs/1706.03762v5" target="_blank">Attention Is All You Need</a>: A Transformer architekt√∫r√°t mutatta be els≈ënek.<br>&#8211; <a rel="noreferrer noopener" href="https://arxiv.org/abs/1706.05137≈±" target="_blank">One Model To Learn Them All</a>: A generaliz√°lt modellek lehet≈ës√©gei</p>



<p>Egy meme az √∂sszes.</p>



<p>A Transformer egy speci√°lis attention-t haszn√°l, aminek a neve self-attention.</p>



<figure class="wp-block-image aligncenter size-full is-resized"><img decoding="async" src="https://rettend.github.io/wp-content/uploads/2022/12/image-37.png" alt="" class="wp-image-182" width="400"/></figure>



<p>√çme a teljes architekt√∫ra:<br>Input embedding csak egyszer t√∂rt√©nik a feldolgoz√°s el≈ëtt √©s a szavak sz√°mokk√° (igaz√°b√≥l vektorokk√°) val√≥ alak√≠t√°s√°t jelenti, m√©gpedig √∫gy, hogy a hasonl√≥ jelent√©s≈± szavak a training v√©g√©re egym√°shoz k√∂zel lesznek a vektor-t√©rben, tov√°bbi seg√≠ts√©get ny√∫jtva a modellnek. A Positional Encoding egy √∫jabb vektor ad hozz√° a szavakhoz, ami a mondatbeli hely√ºket hivatott t√°rolni. Szint√©n seg√≠ts√©g a modellnek.<br>Az add &amp; norm az √∂sszead√°st √©s a normaliz√°ci√≥t jelenti, √≠gy egyes√≠ti a r√©tegek outputjait egy sz√°mm√°, majd 0 √©s 1 k√∂z√∂tti √©rt√©kre normaliz√°lja, hogy ne szabaduljanak el a sz√°mok a folyamat k√∂zben, valamint jobb teljes√≠tm√©nyhez vezet.<br>√âs a v√©g√©n a softmax hasonl√≥an a kapott √©rt√©keket 0 √©s 1 k√∂z√© teszi, de √∫gy, hogy az √∂sszeg√ºk 1 legyen. √çgy kapunk eredm√©ny√ºl sz√°zal√©kokat.</p>



<figure class="wp-block-image aligncenter size-full is-resized"><img decoding="async" src="https://rettend.github.io/wp-content/uploads/2022/12/image-39.png" alt="" class="wp-image-184" width="400"/></figure>



<p>M√≠g a fejlesztett RNN h√°l√≥zatunkn√°l az attention-t az erre trainelt decoder r√©tegek haszn√°lt√°k fel, itt minden egyes encoder-nek √©s decoder-nek van egy k√ºl√∂n self-attention r√©tege, ami az <strong>√∂sszes </strong>sz√≥ √©s a jelenlegi sz√≥ kapcsolat√°t elemzi. A decoder ezut√°n az encoder attention inform√°ci√≥it is megkapja. Pontosabban az encoder l√°tja az √∂sszes sz√≥t (a m√©g fel nem dolgozottakat is), a decoder csak az eddigieket (Masked).</p>



<figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="879" height="279" src="https://rettend.github.io/wp-content/uploads/2022/12/image-41.png" alt="" class="wp-image-186"/></figure>



<p>Itt egy konkr√©t p√©lda: a mondatban a &#8220;kicked&#8221; sz√≥n√°l vagyunk √©s a t√∂bbi sz√≥val val√≥ kapcsolata l√°that√≥. Ez egy m√≥dja ahogy elk√©pzelhetj√ºk azt:</p>



<figure class="wp-block-image aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="https://rettend.github.io/wp-content/uploads/2022/12/image-42.png" alt="" class="wp-image-189" width="602" height="421"/></figure>



<p>Oh √©s √≠gy minden sz√≥ p√°rhuzamosan feldolgozhat√≥. <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f92d.png" alt="ü§≠" class="wp-smiley" style="height: 1em; max-height: 1em;" /><br>Egy kis k√ºl√∂nbs√©g van m√©g a val√≥di m≈±k√∂d√©sn√©l, mivel a Transformer m√°trixokat haszn√°l, azaz t√∂bb vektort a kapcsolat le√≠r√°s√°ra. Ez a multihead-attention. Ennek k√∂vetkezt√©ben minden sz√≥ra k√ºl√∂nb√∂z≈ë &#8220;t√≠pus√∫&#8221; figyelmet ford√≠tunk (azon t√∫l, hogy k√ºl√∂nb√∂z≈ë √©rt√©k≈±, amit a sz√≠n er≈ëss√©ge jelez).</p>



<figure class="wp-block-image aligncenter size-full"><img decoding="async" loading="lazy" width="602" height="333" src="https://rettend.github.io/wp-content/uploads/2022/12/image-43.png" alt="" class="wp-image-191"/></figure>



<figure class="wp-block-image aligncenter size-full"><img decoding="async" loading="lazy" width="602" height="323" src="https://rettend.github.io/wp-content/uploads/2022/12/image-44.png" alt="" class="wp-image-192"/></figure>



<figure class="wp-block-image aligncenter size-full"><img decoding="async" loading="lazy" width="602" height="346" src="https://rettend.github.io/wp-content/uploads/2022/12/image-45.png" alt="" class="wp-image-193"/></figure>



<p>Az RNN √©s CNN h√°l√≥zatok m√©g egy eddig nem eml√≠tett h√°tr√°nya, hogy mindig egy adott hossz√∫s√°g√∫ input vektort ig√©nyelnek, vagy √∫gynevezett pre-processing m≈±veleteket kell haszn√°lni, amik √°tform√°lj√°k az adatokat. A Transformer ezzel ellent√©tben j√≥l megvan a self-attention-j√©vel b√°rmilyen inputtal, viszont megeml√≠tend≈ë, hogy ez hamar teljes√≠tm√©nyroml√°shoz vezet.</p>



<p>Ez h√°t a Transformer, de t√©nyleg csak ennyire lenne k√©pes? Nem. Meglep≈ëen ez a megk√∂zel√≠t√©s m√°s feladatokra is alkalmazhat√≥, s≈ët a legt√∂bbre. A Transformer egy √°ltal√°nos modell lett, amit nagyon k√ºl√∂nb√∂z≈ë probl√©m√°kra haszn√°lnak. Ez az√©rt nagy dolog, mivel ezzel most els≈ënek egy olyan modell hozhat√≥ l√©tre ami k√©pes az inform√°ci√≥ √©rtelmez√©s√©re minden m√©diumban: sz√∂veg, hang, k√©p, vide√≥. Ez nagy l√©p√©s az AGI fel√©. Ide kapcsol√≥dik a <a rel="noreferrer noopener" href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html" target="_blank">The Bitter Lesson</a> poszt is.</p>



<p>√âs most egy r√∂vid recap: 2022-es Karpathy (opcion√°lisan megn√©zhet≈ë az eg√©sz vide√≥ de el√©g 33:34-47:21-ig).</p>



<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe loading="lazy" title="Andrej Karpathy: Tesla AI, Self-Driving, Optimus, Aliens, and AGI | Lex Fridman Podcast #333" width="500" height="281" src="https://www.youtube.com/embed/cdiD-9MMpb0?start=2014&#038;feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div></figure>



<p>Az AI j√∂v≈ëj√©r≈ël m√©g:</p>



<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe loading="lazy" title="OpenAI CEO Sam Altman |  AI for the Next Era" width="500" height="281" src="https://www.youtube.com/embed/WHoWGNQRXb0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div></figure>



<p>M√°r l√°ttuk <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Moore's_law" target="_blank">Moore &#8220;t√∂rv√©ny√©t&#8221;</a>, miszerint kb. 2 √©vente megdupl√°z√≥dik az egys√©gnyi ter√ºletre jut√≥ tranzisztorok sz√°ma. Nem kis dolog, ilyen exponenci√°lis n√∂veked√©s kev√©s helyen figyelhet≈ë meg. Hogy meg√©rts√ºk mekkora hat√°sa lesz az AI-nak k√©pzelj√ºk el a k√∂vetkez≈ët: <a rel="noreferrer noopener" href="https://moores.samaltman.com/" target="_blank">Moore&#8217;s Law for Everything</a>. <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f440.png" alt="üëÄ" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>



<p>A v√©g√©n n√©zz√ºnk meg p√°r √©rdekes, √©s m√°r el√©rhet≈ë men≈ë dolgot.</p>



<p class="has-medium-font-size">ChatGPT</p>



<p>GPT-3 lesz az alapja nagyon sok j√∂v≈ëbeli modellnek. Addigis haszn√°lhatjuk a <a rel="noreferrer noopener" href="https://chat.openai.com/" target="_blank">ChatGPT</a>-t! Nagyon hasznos chatbot ami k√©pes b√°rmit elmagyar√°zni. B√°r ez egy side project, el√©g h√≠res lett √©s egy h√©t alatt az 1M user-t is √°tl√©pte, ami nem v√©letlen. Azont√∫l, hogy t√©nyleg b√°rmit el tud magyar√°zni tetsz√©s√ºnk szerint (√©s mivel GPT tudjuk hogy minden nyelven tud), sok vicces dologra is k√©pes. Pl. nagyon szereti a fa vicceket √©s h√°t, k√©pes <em>m√°s</em> dolgokra is.</p>



<div class="is-layout-flex wp-container-6 wp-block-columns">
<div class="is-layout-flow wp-block-column" style="flex-basis:66.66%">
<figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="1284" height="1193" src="https://rettend.github.io/wp-content/uploads/2022/12/image-49.png" alt="" class="wp-image-200"/></figure>
</div>



<div class="is-layout-flow wp-block-column" style="flex-basis:33.33%">
<figure class="wp-block-image size-full is-resized"><img decoding="async" loading="lazy" src="https://rettend.github.io/wp-content/uploads/2022/12/image-47.png" alt="" class="wp-image-198" width="154" height="385"/></figure>
</div>
</div>



<figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="891" height="410" src="https://rettend.github.io/wp-content/uploads/2022/12/image-50.png" alt="" class="wp-image-201"/></figure>



<p>Els≈ënek neh√©z lehet meggy≈ëzni hogy ne kezdjen el tiltakozni, hogy ≈ë csak egy language model, de ut√°na bele tud j√∂nni.</p>



<div class="is-layout-flex wp-container-9 wp-block-columns">
<div class="is-layout-flow wp-block-column" style="flex-basis:33.33%">
<figure class="wp-block-image size-full is-resized"><img decoding="async" loading="lazy" src="https://rettend.github.io/wp-content/uploads/2022/12/image-53.png" alt="" class="wp-image-204" width="227" height="96"/></figure>
</div>



<div class="is-layout-flow wp-block-column" style="flex-basis:66.66%">
<figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="432" height="435" src="https://rettend.github.io/wp-content/uploads/2022/12/image-52.png" alt="" class="wp-image-203"/></figure>



<p class="has-text-align-center has-cyan-bluish-gray-color has-text-color" style="margin-top:0px">≈ë mondta</p>
</div>
</div>



<p>Tud t√°rsasj√°t√©kokat kital√°lni, am≈ëb√°zni, √©s szerepj√°t√©kozni is lehet vele: <a href="https://imgur.com/a/SrBOabj" target="_blank" rel="noreferrer noopener">https://imgur.com/a/SrBOabj</a></p>



<p>√â√©√©√©s valaki azt is elhitette vele, hogy egy virtu√°lis g√©p: <a rel="noreferrer noopener" href="https://www.engraved.blog/building-a-virtual-machine-inside/" target="_blank">Building A Virtual Machine inside ChatGPT</a>.</p>



<p>Hasonl√≥ oldal: <a rel="noreferrer noopener" href="https://beta.character.ai/" target="_blank">Character.AI</a>.</p>



<p>A ChatGPT-vel egy√ºtt kij√∂tt a GPT-3.5, de k√©sz√ºl≈ëdik a GPT-4 is!<br>√ögy n√©z ki a Turing teszt m√°r nem tart ki sok√°ig.</p>



<figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"><div class="wp-block-embed__wrapper">
<blockquote class="twitter-tweet" data-width="500" data-dnt="true"><p lang="zxx" dir="ltr"><a href="https://t.co/Io0OXbNPzi">pic.twitter.com/Io0OXbNPzi</a></p>&mdash; Sam Altman (@sama) <a href="https://twitter.com/sama/status/1590416386765254656?ref_src=twsrc%5Etfw">November 9, 2022</a></blockquote><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div></figure>



<p class="has-medium-font-size">Image generation</p>



<p>Egy m√°sik nagy r√©sze az AI-nak amir≈ël m√©g nem esett sz√≥ itt, az a diffusion modell. A Stable Diffusion modell a Stability AI eredm√©nye, ami k√©pes k√©peket gener√°lni sz√∂veges inputb√≥l. Ennek is √©rdemes ut√°nan√©zni mert hatalmas. Erre √©p√ºlt m√°r p√°r el√©rhet≈ë app is:</p>



<ul class="has-small-font-size">
<li><a rel="noreferrer noopener" href="https://openai.com/dall-e-2/" target="_blank">Dall-E 2</a> (OpenAI): bejelentkez√©s ut√°n haszn√°lhat√≥ is, de csak korl√°tozottan (havi kreditek). az Outpainting a legjobb feature-je.</li>



<li><a rel="noreferrer noopener" href="https://imagen.research.google/" target="_blank">Imagen </a>(Google): nincs el√©rhet≈ë demo bel≈ële. Rip.</li>



<li><strong>Midjourney</strong>: 2022 j√∫lius√°ban jelent meg √©s Discordon egy bottal haszn√°lhat√≥. Korl√°tozottabb mint a Dall-E (nem t√∂lt≈ëdnek vissza a kreditek), de az √∫j verzi√≥val (V4) nagyon kreat√≠v k√©peket gener√°l. P√°r h√≥nap alatt ez lett a legnagyobb Discord szerver (5M user-rel, m√≠g a szerver a 2. helyen 1M user-n√©l van), sz√≥val nem kis dolog.</li>
</ul>



<p>M√©g egy j√≥ demo, havi kreditekkel: <a href="https://stableboost.ai/home">Stableboost</a>.</p>



<p>√öjabban a Stable Diffusion 2 is el√©rhet≈ë lett ami szint√©n kir√°ly √∫j√≠t√°sokat hozott.<br>√âs el√©rhet≈ë Hugging Face-n is! Ott lehet a diffusion modellekr≈ël tanulni tov√°bb.</p>



<p>Nem kell sok id≈ë amire a val√≥s√°gh≈± k√©pgener√°l√°st√≥l eljutunk a vide√≥k, filmek √©s 3d-s modellek gener√°l√°s√°ig.</p>



<p>Kicsit a vesz√©lyeir≈ël is. A paperclip maximizer. </p>



<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe loading="lazy" title="AI&#039;s Deadly Paperclips" width="500" height="281" src="https://www.youtube.com/embed/rgrCG8PT6og?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div></figure>



<p>√âs nem hittem, hogy egy Ted vide√≥t is be fogok tenni:</p>



<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe loading="lazy" title="What happens when our computers get smarter than we are? | Nick Bostrom" width="500" height="281" src="https://www.youtube.com/embed/MnT1xgZgkpk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div></figure>



<p>K√∂vetkez≈ë poszt: <a href="https://rettend.github.io/2022/12/07/grind/" target="_blank" rel="noreferrer noopener">THE GRIND</a></p>
]]></content:encoded>
					
					<wfw:commentRss>https://rettend.github.io/2022/12/06/transformer/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>It&#8217;s 2022 and you&#8217;re in the future</title>
		<link>https://rettend.github.io/2022/11/29/future/</link>
					<comments>https://rettend.github.io/2022/11/29/future/#respond</comments>
		
		<dc:creator><![CDATA[root]]></dc:creator>
		<pubDate>Tue, 29 Nov 2022 16:47:13 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">https://rettend.github.io/?p=29</guid>

					<description><![CDATA[Amikor els≈ënek olvastam el a Software 2.0-s blogposztot, √∫gy voltam vele, hogy &#8220;Aha, majd 10 √©v m√∫lva visszat√©rhet√ºnk r√°.&#8221; Nos, hamar kider√ºlt, hogy nem tudtok semmit. 3 dolog t√∂rt√©nt ugyanis az√≥ta: ü§ó Hugging Face, GitHub Copilot √©s a Transformer model. Papi szeretne valamit mondani: Sz√≥val a szoftver eszi a F√∂ldet, az AI pedig a szoftvert, [&#8230;]]]></description>
										<content:encoded><![CDATA[
<figure class="wp-block-image aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="https://rettend.github.io/wp-content/uploads/2022/11/stick-ninja-waving-2.png" alt="" class="wp-image-16" width="256" height="256"/></figure>



<p class="has-small-font-size">Amikor els≈ënek olvastam el a Software 2.0-s blogposztot, √∫gy voltam vele, hogy &#8220;Aha, majd 10 √©v m√∫lva visszat√©rhet√ºnk r√°.&#8221; Nos, hamar kider√ºlt, hogy nem tudtok semmit. 3 dolog t√∂rt√©nt ugyanis az√≥ta:</p>



<p class="has-small-font-size"><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f917.png" alt="ü§ó" class="wp-smiley" style="height: 1em; max-height: 1em;" /> Hugging Face, GitHub Copilot √©s a Transformer model.</p>



<p class="has-small-font-size">Papi szeretne valamit mondani:</p>



<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe loading="lazy" title="Machine learning for developers with GitHub and Hugging Face - Universe 2022" width="500" height="281" src="https://www.youtube.com/embed/qd19W227W6c?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div></figure>



<p>Sz√≥val a szoftver eszi a F√∂ldet, az AI pedig a szoftvert, √©s nemtom, hogy vagy vele, de szerintem jobb a t√°pl√°l√©kl√°nc legtetej√©n lenni&#8230;</p>



<p class="has-small-font-size">Okay a Hugging Face a Software 2.0 GitHub, √©s egy nagyon hasznos hely az alkalmaz√°s-fejleszt√©shez, b√°r m√©g csak kezdeti f√°zisban van, √©s van hova fejl≈ëdnie.</p>



<p class="has-small-font-size">T√©rj√ºnk r√° a Copilot-ra. Remember <a rel="noreferrer noopener" href="https://miro.medium.com/max/750/1*7aTCueMW8oBRiqkyobunVA.webp" target="_blank">gradient descent</a>? This is him now.<br>Ha m√©g semmit se hallott√°l volna r√≥la, akkor l√©nyeg√©ben olyan mint az IntelliSense, csak sokkal t√∂bb, egy nagyon Smart Ctrl C + Ctrl V. <br>A k√∂vetkez≈ë egy nagyon hossz√∫ 8 perc lesz.</p>



<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe loading="lazy" title="How GitHub Copilot can impact developer happiness - Universe 2022" width="500" height="281" src="https://www.youtube.com/embed/jr38-yiTr8k?list=PL0lo9MOBetEGWpxPIXR8I46O-HHV7JbrU" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div></figure>



<p class="has-small-font-size"><br>Hallgassuk meg Guido van Rossum (creator of Python) v√©lem√©ny√©t is.</p>



<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe loading="lazy" title="Guido van Rossum on GitHub Copilot: It helps take care of the boring stuff | Lex Fridman" width="500" height="281" src="https://www.youtube.com/embed/_KjSkGgaJ1k?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div></figure>



<p class="has-small-font-size">Az utols√≥ amit el szeretn√©k mondani miel≈ëtt r√°t√©r√ºnk a fincsi r√©szre, hogy ez  a Software 2.0 fel√© az els≈ë l√©p√©s, √©s k√∂r√ºlbel√ºl olyan mint amikor mindenki (illetve csak nagyon kev√©s hozz√°√©rt≈ë ember) m√©g low-level progi nyelveket haszn√°lt. Majd mikor kezdtek megjelenni a high-level programoz√°si nyelvek, akkor bizony√°ra hasonl√≥ dolog mer√ºlhetett fel sokakban, hogy &#8220;akkor most mindenki fog tudni programozni √©s nem lesz munk√°nk?&#8221;. Ehelyett pont az ellenkez≈ëje t√∂rt√©nt: ugyan ez az √∫j absztrakci√≥ szint lehet≈ëv√© tette, hogy rengetegen elkezdj√©k a programoz√°st, m√©g ann√°l is t√∂bb munkahely j√∂tt l√©tre √©s kib≈ëv√ºltek a lehet≈ës√©gek.</p>



<p class="has-small-font-size">√âs akkor j√∂jj√∂n a r√°hangol√≥d√°s. A Copilot alapb√≥l fizet≈ës, de van egy kis hack erre: di√°koknak ingyenes. <a rel="noreferrer noopener" href="https://education.github.com/pack" target="_blank">Itt a link</a>, ahol egy matric√°s di√°kigazolv√°nyt vagy valami hasonl√≥t kell befot√≥zni √©s m√©g egy csom√≥ m√°s cuccot is adnak (pl. GitHub Pro). Ezut√°n a Visual Studio √©s/vagy a VS Code <a rel="noreferrer noopener" href="https://marketplace.visualstudio.com/items?itemName=GitHub.copilot" target="_blank">extension</a>-t kell let√∂lten√ºnk √©s haszn√°lhatjuk is.<br>Egyszer≈± kezelni is, de r√° kell j√∂nni, hogy mi√©rt azt csin√°lja, amit √©ppen csin√°l, √©s erre a legjobb ha szimpl√°n elkezdj√ºk haszn√°lni mindig amikor programozunk. Itt most az√©rt r√©szletesebben is megn√©zz√ºk.</p>



<figure class="wp-block-image size-full is-resized"><img decoding="async" loading="lazy" src="https://rettend.github.io/wp-content/uploads/2022/12/thanks-copilot-1.png" alt="" class="wp-image-89" width="526" height="380"/></figure>



<p class="has-text-align-center has-cyan-bluish-gray-color has-text-color" style="margin-top:0px">GitHub Copilot being very useful</p>



<p>Els≈ënek is, amikor elkezd√ºnk g√©pelni, akkor halv√°nyan megjelenik egy javaslat Copilot-t√≥l, amit a TAB-al tudunk elfogadni. Ha r√°vissz√ºk az egeret erre a sz√∂vegre, akkor tov√°bbi lehet≈ës√©geket is mutat. </p>



<p>Itt megpr√≥b√°ljuk √°tvenni egy AI modell gondolkod√°s√°t, vagyis csak megmutatom, hogy hogy n√©z ki egy k√©sz app ami AI-t haszn√°l. Na de √°ssuk is bele magunkat, mit tud √©s mit nem, valamint, hogy milyen √∫j√≠t√°sok v√°rhat√≥k r√°.</p>



<p class="has-tertiary-background-color has-background" style="margin-top:var(--wp--preset--spacing--20);margin-right:var(--wp--preset--spacing--20);margin-bottom:var(--wp--preset--spacing--20);margin-left:var(--wp--preset--spacing--20);padding-top:var(--wp--preset--spacing--20);padding-right:var(--wp--preset--spacing--20);padding-bottom:var(--wp--preset--spacing--20);padding-left:var(--wp--preset--spacing--20)">A Copilot egy OpenAI √°ltal √∂sszerakott modellre √©p√ºl, a <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/GPT-3" target="_blank">GPT-3</a>-ra (Generative Pre-trained <strong>Transformer</strong>). Ez egy hatalmas transformer modell, amit f≈ëleg az interneten traineltek (mi baj lehetne). A pap√≠rj√°ban (<a rel="noreferrer noopener" href="https://arxiv.org/abs/2005.14165" target="_blank">Language Models are Few-Shot Learners</a>) egy csom√≥ n√©v fel van t≈±ntetve, √©s a fejleszt≈ëi bemutatj√°k, hogy egy ilyen hatalmas modellel el√©g ha p√°rszor l√°t az egy inform√°ci√≥t, m√°r √∫gy is meg tudja tanulni (few-shot learning). Ami miatt nagy dolog az az, hogy nagyon j√≥l &#8220;meg√©rti&#8221; az √≠rott sz√∂vegeket √©s nagyon hihet≈ë v√°laszokat tud gener√°lni. Ez azonban ugyan√∫gy csak egy language model, ez√©rt az egyetlen dolog, ami ≈ët √©rdekli, hogy ha kap egy sz√∂veges inputot, akkor mi az ami a legval√≥sz√≠n≈±bb, hogy azt k√∂veti a tanult inform√°ci√≥k alapj√°n: ha van 1000 karakter, akkor mi az 1001-edik √©s az 1002-edik. Ennyi. √Åm ezzel hihetetlen√ºl messze el lehet jutni, valamint a m√∂g√∂tte rejl≈ë transformer architekt√∫r√°nak k√∂sz√∂nhet≈ëen (a Transformer-r≈ël k√ºl√∂n fejezet sz√≥l) k√©pes a megfelel≈ë szavakra nagyobb figyelmet ford√≠tani (attention mechanics). √çgy nemcsak, hogy a nyelvtani szerkezetre tud r√°j√∂nni √©s helyes szavakat gener√°lni, hanem azt √©rthet≈ëen, √∂sszef√ºgg≈ëen √©s nagyon sok nyelven. Mik√∂zben az egyszer≈± feladat√°t v√©gzi, hogy kital√°lja az egym√°st k√∂vet≈ë szavakat, olyan komplex probl√©m√°kat tud megoldani, amik minket √©rdekelnek, √©s nemr√©g m√©g kiv√©tel n√©lk√ºl az emberi kreativit√°s al√° tartoztak.<br><br>Azt√°n ebb≈ël sz√°rmazik a <a rel="noreferrer noopener" href="https://openai.com/blog/openai-codex/" target="_blank">Codex</a>, amivel egy l√©p√©ssel tov√°bbmentek, √©s a natural language mellett, GitHub-on el√©rhet≈ë milli√°rd sornyi nyilv√°nos k√≥don tan√≠tott√°k. √çgy azon t√∫l, hogy meg√©rti az emberi nyelvet, m√°r a programoz√°si nyelveken is tud (szintaktikailag helyes k√≥dot tud gener√°lni) √©s ezek k√∂z√∂tt k√∂nnyed√©n ford√≠t! √âs ez az amire a Copilot √©p√ºl, valamint azt is fogjuk l√°tni, hogy a GPT-3 limit√°ci√≥it is mag√°val hozza.</p>



<p>De mit is √©r√ºnk az alatt, hogy √©rti a sz√∂vegeket? Egyszer≈±: kommentek. A legfelt≈±n≈ëbb funkci√≥ja, hogy ha le√≠rjuk, hogy mit szeretn√©nk csin√°lni, akkor ahhoz feldobja a k√≥dot.</p>



<div class="has-global-padding is-layout-constrained wp-block-group">
<div class="is-layout-flex wp-container-13 wp-block-columns">
<div class="is-layout-flow wp-block-column" style="flex-basis:100%">
<figure class="is-layout-flex wp-block-gallery-10 wp-block-gallery has-nested-images columns-default is-cropped">
<figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="432" height="74" src="https://rettend.github.io/wp-content/uploads/2022/12/image-4.png" alt="" class="wp-image-94"/></figure>



<figure class="wp-block-image size-full has-custom-border is-style-default"><img decoding="async" loading="lazy" width="691" height="138" src="https://rettend.github.io/wp-content/uploads/2022/12/image-2.png" alt="" class="wp-image-92" style="border-style:none;border-width:0px;border-radius:0px"/></figure>
</figure>
</div>
</div>
</div>



<figure class="wp-block-image size-full is-resized"><img decoding="async" loading="lazy" src="https://rettend.github.io/wp-content/uploads/2022/12/image-6.png" alt="" class="wp-image-96" width="273" height="146"/></figure>



<p>√Åltal√°ban a sorokat csak egyes√©vel, de ahol egy scope-ba bel√©p√ºnk, ott azt le tudja teljesen gener√°lni. A l√©nyeg, hogy min√©l t√∂bb contextust adjunk neki, ez lehet ugye kommenteken kereszt√ºl, de a v√°ltoz√≥ √©s function nevek, √©s a k√≥dunk maga is sokat seg√≠t. Ami egyb≈ël felt≈±nhet, hogy mivel csak egy list√°t folytat ami szavakb√≥l √©s karakterekb≈ël √°ll, ez√©rt figyelmen k√≠v√ºl hagyja azt, ami az ut√°ni sorokban van (persze erre lenn√©nek megold√°sok, de m√©g v√°rnunk kell r√°juk):</p>



<figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="289" height="194" src="https://rettend.github.io/wp-content/uploads/2022/12/image-7.png" alt="" class="wp-image-97"/></figure>



<p class="has-text-align-center has-cyan-bluish-gray-color has-text-color" style="margin-top:0px;font-size:14px">Liter√°lisan 2 sorral lennebb van a discord library de beimport√°ln√° m√©gegyszer</p>



<p>Ami miatt Smart Ctrl C + Ctrl V-nek lehet nevezi, az az, hogy a k√≥dunkat amit folytat azt k√∂zben √©rtelmezi (ha akarja ha nem, nem tud m√°st csin√°lni), √≠gy nagyon szeret lem√°solni dolgokat √∫gy, hogy a megfelel≈ë v√°ltoz√≥neveket haszn√°lja. De k√©pes a m√°r l√©trehozott function-√∂k helyes felhaszn√°l√°s√°ra is. Ahol egy mint√°t kell folytatni, ott Copilot mindig jeleskedik.</p>



<figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="1087" height="191" src="https://rettend.github.io/wp-content/uploads/2022/12/image-8.png" alt="" class="wp-image-98"/></figure>



<p class="has-text-align-center has-cyan-bluish-gray-color has-text-color" style="margin-top:0px">El√©g template k√≥d lett, a footer sz√∂vege sz√≥ szerint &#8220;Footer text&#8221;</p>



<figure class="wp-block-image size-full is-resized"><img decoding="async" loading="lazy" src="https://rettend.github.io/wp-content/uploads/2022/12/image-9.png" alt="" class="wp-image-99" width="740" height="214"/></figure>



<p>Azonban ez egy language model m√©g mindig, √≠gy m√©g valamit nem csin√°l, nem ellen≈ërzi, hogy a gener√°lt k√≥d val√≥ban lefutna-e, s≈ët Copilot-ot az se √©rdekli, hogy nincs is olyan attachment amit haszn√°lni akar:</p>



<figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="809" height="403" src="https://rettend.github.io/wp-content/uploads/2022/12/image-10.png" alt="" class="wp-image-100"/></figure>



<p class="has-text-align-center has-cyan-bluish-gray-color has-text-color" style="margin-top:0px">1234567890 <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f914.png" alt="ü§î" class="wp-smiley" style="height: 1em; max-height: 1em;" /><img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f914.png" alt="ü§î" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>



<p>Egyszer≈±en az izgatja, hogy sok olyan √ºzenetet l√°tott, ahol egy k√©pet is raktak hozz√° √©s egy k√©p id-ja valami ilyen form√°ban van. Arr√≥l nem is besz√©l√ºnk, hogy ez a r√©gi m√≥dja egy discord bot √≠r√°s√°nak Pythonban, az√≥ta m√°r √∫jra√≠rt√°k az eg√©sz library-t, de mivel ezzel van m√©g tele a GitHub √©s nem is voltunk t√∫l konkr√©tak, ezt kaptuk t≈ële. Hagyom is a botos p√©ld√°t.</p>



<p>Na de az√©rt nagyon satisfying tud lenni a TAB le√ºt√©se.</p>



<figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="592" height="248" src="https://rettend.github.io/wp-content/uploads/2022/12/image-22.png" alt="" class="wp-image-133"/></figure>



<p class="has-text-align-center has-cyan-bluish-gray-color has-text-color" style="margin-top:0px">&#8220;No <strong><code>this</code>, </strong>No that&#8221;</p>



<p>Viszont a Copilot m√©g sok praktikus dolgot tud, f≈ëleg ha esetleg egy megkezdett projekthez haszn√°ljuk, ugyanis k√©pes nagyon komplex mint√°kat folytatni, sim√°n √°tveszi a haszn√°lt coding style-unkat is (pl. camelCase-t vagy PascalCase-t haszn√°ltunk egy <em>f√©le </em>v√°ltoz√≥hoz). S≈ët nem csak azt a f√°jlt n√©zi amiben dolgozunk, hanem megpr√≥b√°l min√©l t√∂bbet (ami f√°jlok meg vannak nyitva, azokat nagyobb es√©llyel figyeli).</p>



<p>Nagyon hasznos m√©g amikor z√°r√≥jeleket kell befejezni (tudom rossz p√©lda mert egy sorban van, ez programoz√°s k√∂zben √∫gy n√©z ki, hogy TAB, Enter, TAB, Enter, TAB √©s t√∂k√©letesen le van z√°rva a f√ºggv√©ny.</p>



<figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="423" height="31" src="https://rettend.github.io/wp-content/uploads/2022/12/image-19.png" alt="" class="wp-image-128"/></figure>



<p>Valamint a RegEx kifejez√©seket se l√∂vi meg:</p>



<figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="431" height="66" src="https://rettend.github.io/wp-content/uploads/2022/12/image-20.png" alt="" class="wp-image-129"/></figure>



<figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="431" height="275" src="https://rettend.github.io/wp-content/uploads/2022/12/image-21.png" alt="" class="wp-image-130"/></figure>



<p>Az emberi √©s a programoz√°si nyelvek k√∂z√∂tt a m√°sik ir√°nyban is tud dolgozni, √©s l√©nyeg√©ben egy k√≥dr√©szletet tetsz√©s szerint el tud magyar√°zni nek√ºnk.</p>



<figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="1079" height="289" src="https://rettend.github.io/wp-content/uploads/2022/12/image-11.png" alt="" class="wp-image-101"/></figure>



<p>M√©g APL-t is <img src="https://s.w.org/images/core/emoji/14.0.0/72x72/1f607.png" alt="üòá" class="wp-smiley" style="height: 1em; max-height: 1em;" /></p>



<figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="1058" height="271" src="https://rettend.github.io/wp-content/uploads/2022/12/image-12.png" alt="" class="wp-image-102"/></figure>



<p>√âs persze √≠gy tudunk nyelvek k√∂z√∂tt is ford√≠tani. A v√°ltoz√≥neveket meg is hagyta.</p>



<figure class="wp-block-image size-full is-resized"><img decoding="async" loading="lazy" src="https://rettend.github.io/wp-content/uploads/2022/12/image-14.png" alt="" class="wp-image-104" width="521" height="365"/></figure>



<p>√âs lassan kezd√ºnk √°tt√©rni a Copilot j√∂v≈ëj√©re, de el≈ëtte m√©g egy √©rdekes vide√≥:</p>



<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe loading="lazy" title="Building with Codex Fireside Chat - Universe 2022" width="500" height="281" src="https://www.youtube.com/embed/nrW0O0ViipI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div></figure>



<p>Sz√≥val Copilot k√©pes lesz debug-olni √©s ha ki tudja tal√°lni, hogy mit akarunk (pl. json f√°jl egy class-ba √≠r√°sa), akkor tudja tesztelni, hogy azt kaptuk-e amit v√°rtunk (pl. ha nem csak k√∂t≈ëjellel, hanem ponttal is el vannak v√°lasztva a d√°tumok, akkor √©szreveszi √©s lekezelni azt).</p>



<p>√âs erre m√°r van is egy protot√≠pus, kij√∂tt ugyanis m√°r egy m√°sik vs code extension: a <a rel="noreferrer noopener" href="https://marketplace.visualstudio.com/items?itemName=GitHub.copilot-labs" target="_blank">GitHub Copilot Labs</a>, ahol ezeket tesztelhetj√ºk. 3 f√ºl van: explain, language translation √©s brushes. Az utols√≥val a k√≥d gener√°l√°s√°n t√∫l a megl√©v≈ë k√≥db√°zisunk m√≥dos√≠t√°sa is lehets√©ges.</p>



<div class="is-layout-flex wp-container-17 wp-block-columns">
<div class="is-layout-flow wp-block-column">
<figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="345" height="677" src="https://rettend.github.io/wp-content/uploads/2022/12/image-16.png" alt="" class="wp-image-106"/></figure>
</div>



<div class="is-layout-flow wp-block-column">
<figure class="wp-block-image size-full is-resized"><img decoding="async" loading="lazy" src="https://rettend.github.io/wp-content/uploads/2022/12/image-17.png" alt="" class="wp-image-107" width="368" height="419"/></figure>
</div>
</div>



<figure class="wp-block-image size-full"><img decoding="async" loading="lazy" width="493" height="187" src="https://rettend.github.io/wp-content/uploads/2022/12/image-18.png" alt="" class="wp-image-108"/></figure>



<p class="has-cyan-bluish-gray-color has-text-color">Egy√©bk√©nt ezek messze nem m≈±k√∂dnek t√∂k√©letesen, de adhatunk visszajelz√©st (mondjuk nem tudom mit kezden√©nek azzal, hogy √©n SQL query-ket ford√≠ttatok le vele css-re vagy a package.json tartalm√°t vue-ba jahmi).</p>



<p>Copilot √©s a Copilot Labs a k√©t el√©rhet≈ë protot√≠pus eddig, de a GitHub egy hadseregnyi Copilot-ot tervez m√©g k√©sz√≠teni, amiket a <a rel="noreferrer noopener" href="https://githubnext.com/" target="_blank">GitHub Next</a> oldalon gy≈±jtenek. √ârdemes megn√©zni ezt az oldalt, mivel rengeteg k√©p is van hozz√°juk, √©s m√°s GitHub feature-√∂ket is tartalmaz. A leg√©rdekesebbeket √∂sszeszedem ide:</p>



<ul class="has-small-font-size">
<li>TestPilot: k√©pes gener√°lni teszteket k√≥d √©s le√≠r√°s alapj√°n, majd az eredm√©ny alapj√°n jav√≠tani azokon</li>



<li>GitHub Copilot-nak az eg√©sz mapp√°nk el√©rhet≈ëv√© t√©tele: ehhez az kell, hogy ki tudja v√°lasztani, hogy mit vegyen figyelembe, hogy ne vegyen ig√©nybe t√∂bb id≈ët a m≈±k√∂d√©se, ne lassuljon be teljesen</li>



<li>Copilot Radar: turbo go-to-definition, mivel nem mindig a defin√≠ci√≥ √©rdekel minket hanem kommentek, vagy hasonl√≥ el≈ëfordul√°sok ahol ugyanazt haszn√°ljuk</li>



<li>Copilot CLI: parancssoros Copilot, szavakkal le√≠rhatod amit szeretn√©l √©s parancsokk√° ford√≠tja vagy aj√°nl fel</li>
</ul>



<p>K√∂vetkez≈ë poszt: <a href="https://rettend.github.io/2022/12/06/transformer/">Transformer: Meme your way to greatness</a></p>
]]></content:encoded>
					
					<wfw:commentRss>https://rettend.github.io/2022/11/29/future/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Winter is not coming</title>
		<link>https://rettend.github.io/2022/09/29/ai-winter/</link>
					<comments>https://rettend.github.io/2022/09/29/ai-winter/#respond</comments>
		
		<dc:creator><![CDATA[root]]></dc:creator>
		<pubDate>Thu, 29 Sep 2022 21:04:02 +0000</pubDate>
				<category><![CDATA[Uncategorized]]></category>
		<guid isPermaLink="false">https://rettend.github.io/?p=1</guid>

					<description><![CDATA[Els≈ënek is p√°r dologgal tiszt√°ban kell lenned. √âs azok el≈ëtt is tal√°n az AI fogalm√°val. &#8220;AI is whatever hasn&#8217;t been done yet.&#8221; ‚Äî Larry Tesler Igen.. ez egy nagyon f√©lre√©rtett √°gazat, olyannyira hogy m√°r nem is merik defini√°lni. Biztosan hallott√°l r√≥la m√°r valamit, hogy a meg b √©s hogy mennyire nagy dolog. √âs pont ez√©rt [&#8230;]]]></description>
										<content:encoded><![CDATA[
<p class="wp-elements-8cb8aa7c2d304695e98e941c7c658f10 has-link-color has-small-font-size">Els≈ënek is p√°r dologgal tiszt√°ban kell lenned. √âs azok el≈ëtt is tal√°n az AI fogalm√°val.</p>



<blockquote class="wp-block-quote has-small-font-size">
<p class="has-small-font-size">&#8220;AI is whatever hasn&#8217;t been done yet.&#8221;</p>
<cite>‚Äî Larry Tesler</cite></blockquote>



<figure class="wp-block-image aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="https://rettend.github.io/wp-content/uploads/2022/11/stick-ninja-no-comment-2.png" alt="" class="wp-image-17" width="257" height="257"/></figure>



<p class="wp-elements-ff62e1b1121c6748ad2212d1fcc5be56 has-link-color has-small-font-size">Igen.. ez egy nagyon f√©lre√©rtett √°gazat, olyannyira hogy m√°r nem is merik defini√°lni. Biztosan hallott√°l r√≥la m√°r valamit, hogy <em>a</em> meg <em>b</em> √©s hogy mennyire nagy dolog. √âs pont ez√©rt most arra k√©rlek, hogy ezeket mind tedd kicsit f√©lre, mert soooook dolog van amit el szeretn√©k mondani.</p>



<p class="wp-elements-91f51c6edeb2656cd1598d424bf75ff8 has-link-color has-small-font-size">Sz√≥val, az AI el√©g t√°g fogalom: <em>&#8220;Making things smart&#8221;</em>, √©s egy ideje m√°r foglalkoznak vele emberek (id≈ësebb mint az internet). S≈ët, nem is ez az els≈ë, hogy nagyon felkapott lett (<a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/AI_winter" target="_blank">AI winter</a>). Ami most m√°s az kicsit m√©lyebben van:</p>



<figure class="wp-block-image aligncenter size-full is-resized"><img decoding="async" loading="lazy" src="https://rettend.github.io/wp-content/uploads/2022/11/AI_ML_DL_circles-2.png" alt="" class="wp-image-41" width="473" height="488"/></figure>



<p class="has-small-font-size">A Deep Learning (DL) megjelen√©s√©vel j√∂tt el az AI ideje.</p>



<p class="has-small-font-size">Amikor arr√≥l besz√©l√ºnk, hogy neur√°lus h√°l√≥zatok (NN), akkor egy DL modell architekt√∫r√°j√°t √©rtj√ºk ezalatt. Ez neuronok h√°l√≥zata, de egy neuron igaz√°b√≥l csak egy val√≥s sz√°mot ad ki mag√°b√≥l, ami elt√©r≈ë m√≥don befoly√°sol m√°s neuronak, √©s amik √©rt√©k√©t egy algoritmus √°ll√≠tgat. Ennyi. Nagyon nagy vonalakban. √âs ami m√©g meglep≈ëbb, hogy mennyire kev√©s eszk√∂z√ºnk van, amik a h√°l√≥zat &#8220;tanul√°s√°t&#8221; val√≥s√≠tj√°k meg: gradient descent √©s backpropagation. Ezekr≈ël az utols√≥ fejezetben. Amiket ha m√°r megeml√≠tettem, akkor a fejezetek l√©nyege:</p>



<ol class="has-small-font-size">
<li>K√≠v√°ncsis√°g felkelt√©se</li>



<li>Gondolkodjunk √∫gy mint egy modell Copilot-tal</li>



<li>Transformer-rel a h√°l√≥zat architekt√∫r√°k m≈±k√∂d√©se felsz√≠nesen</li>



<li>A legm√©lyebb szinten eggy√© v√°lunk a h√°l√≥zatokkal √©s tov√°bbi anyagok</li>
</ol>



<p>Teh√°t mindegyikben ugyanazt fogjuk v√©gign√©zni csak egy szinttel lennebb mindig. Na de visszat√©rve:</p>



<p class="wp-elements-038a6fce738c92f38d08e62c521f698c has-link-color has-small-font-size">B√°rmikor valami nagy dolgot √©rt el valaki &#8211; p√©ld√°ul AlphaZero legy≈ëzi a vil√°gbajnok sakkj√°t√©kost &#8211; az emberek els≈ë reakci√≥ja az, hogy:<em> &#8220;Ez nem igazi intelligencia, csak v√©gig pr√≥b√°lgatta az √∂sszes lehets√©ges l√©p√©st!&#8221;</em>. Egysz√≥val kiker√ºl az AI hat√≥k√∂r√©b≈ël √©s akkor m√°r √©rthet≈ë a fenti Larry Tesler id√©zet.</p>



<p class="has-small-font-size">Ugyan√≠gy minden DL modellr≈ël elmondhat√≥, hogy <em>&#8220;nem igazi intelligencia, csak matek&#8221;</em>, az a probl√©ma viszont most, hogy az emberi agy se sokkal t√∂bb enn√©l. A val√≥s√°g az, hogy mi emberek k√ºl√∂nlegesnek √©rezz√ºk magunkat, √©s ha valami ezt megk√©rd≈ëjelezi, akkor arra hevesen reag√°lunk. √âs ennek az eredm√©nye az <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/AI_effect" target="_blank">AI effect</a>.</p>



<p class="has-small-font-size">De ha minden AI rendszer alapja csak skal√°ris szorzat rengeteg dimenzi√≥ban √©s m√°trix m≈±veletek, akkor m√©gis, hogy lehets√©ges amir≈ël Andrej Karpathy besz√©lt m√©g igaz√°b√≥l karrierje elej√©n:</p>



<figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"><div class="wp-block-embed__wrapper">
<iframe loading="lazy" title="Building the Software 2 0 Stack (Andrej Karpathy)" width="500" height="281" src="https://www.youtube.com/embed/y57wwucbXR8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div></figure>



<p class="has-small-font-size">Kicsit m√°s megk√∂zel√≠t√©ssel ugyanerr≈ël egy blog: <a rel="noreferrer noopener" href="https://karpathy.medium.com/software-2-0-a64152b37c35" target="_blank">Software 2.0</a></p>



<p class="has-small-font-size">K√∂vetkez≈ë poszt: <a href="https://rettend.github.io/2022/11/29/future/" data-type="post">It‚Äôs 2022 and you‚Äôre in the future</a></p>
]]></content:encoded>
					
					<wfw:commentRss>https://rettend.github.io/2022/09/29/ai-winter/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
	</channel>
</rss>
